{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.metrics import  classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding,  Conv1D, MaxPooling1D, GlobalAveragePooling1D,  Flatten, GRU, SpatialDropout1D, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import  regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.comment\n",
    "X_test = test.comment\n",
    "y_train = train[\"label\"]\n",
    "y_test = test[\"label\"]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_test = label_encoder.fit_transform(y_test)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "max_words = len(tokenizer.word_index) + 1  \n",
    "\n",
    "max_len = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter value\n",
    "batch_size = 128\n",
    "embedding_size =100\n",
    "# Convolution\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize Text\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11320, 100) (2831, 100)\n"
     ]
    }
   ],
   "source": [
    "# sequence padding \n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history=None, figure_directory=None, ylim_pad=[0, 0]):\n",
    "    xlabel = 'Epoch'\n",
    "    legends = ['Training', 'Validation']\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    y1 = history.history['accuracy']\n",
    "    y2 = history.history['val_accuracy']\n",
    "\n",
    "    min_y = min(min(y1), min(y2))-ylim_pad[0]\n",
    "    max_y = max(max(y1), max(y2))+ylim_pad[0]\n",
    "\n",
    "\n",
    "    plt.subplot(121)\n",
    "\n",
    "    plt.plot(y1)\n",
    "    plt.plot(y2)\n",
    "\n",
    "    plt.title('Model Accuracy\\n', fontsize=17)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel('Accuracy', fontsize=15)\n",
    "    plt.ylim(min_y, max_y)\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.grid()\n",
    "\n",
    "    y1 = history.history['loss']\n",
    "    y2 = history.history['val_loss']\n",
    "\n",
    "    min_y = min(min(y1), min(y2))-ylim_pad[1]\n",
    "    max_y = max(max(y1), max(y2))+ylim_pad[1]\n",
    "\n",
    "\n",
    "    plt.subplot(122)\n",
    "\n",
    "    plt.plot(y1)\n",
    "    plt.plot(y2)\n",
    "\n",
    "    plt.title('Model Loss\\n', fontsize=17)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel('Loss', fontsize=15)\n",
    "    plt.ylim(min_y, max_y)\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.grid()\n",
    "    if figure_directory:\n",
    "        plt.savefig(figure_directory+\"/history\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1= Sequential()\n",
    "model1.add(Embedding(max_words, embedding_size, input_length=max_len))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Conv1D(256, kernel_size=3,padding='same',activation='relu',strides=1))\n",
    "model1.add(GlobalAveragePooling1D())\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(\n",
    "    units=128,\n",
    "    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "    bias_regularizer=regularizers.l2(1e-4),\n",
    "    activity_regularizer=regularizers.l2(1e-5)\n",
    "))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(2,activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model1.summary()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "history3=model1.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=2, batch_size=batch_size, verbose=1)\n",
    "\n",
    "\n",
    "# Generate predictions on the test set\n",
    "Y_pred = model1.predict(X_test)\n",
    "# Convert predictions from one-hot encoding to class labels\n",
    "Y_pred_labels = np.argmax(Y_pred, axis=1)\n",
    "Y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(Y_true_labels, Y_pred_labels))\n",
    "\n",
    "\n",
    "# Visualization\n",
    "plot_performance(history=history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Embedding(max_words, embedding_size, input_length=max_len))\n",
    "model4.add(Conv1D(256, kernel_size=3, padding='same', activation='relu'))\n",
    "model4.add(MaxPooling1D(pool_size=2))\n",
    "model4.add(Conv1D(256, kernel_size=3, padding='same', activation='relu'))\n",
    "model4.add(MaxPooling1D(pool_size=2))\n",
    "model4.add(Dropout(0.25))\n",
    "model4.add(SpatialDropout1D(0.25))\n",
    "model4.add(Bidirectional(GRU(256, return_sequences=True))) \n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(2, activation='softmax', kernel_regularizer=l2(0.001)))\n",
    "model4.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])\n",
    "model4.summary()\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "history3=model4.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=1, batch_size=batch_size, verbose=1)\n",
    "# Generate predictions on the test set\n",
    "Y_pred = model4.predict(X_test)\n",
    "# Convert predictions from one-hot encoding to class labels\n",
    "Y_pred_labels = np.argmax(Y_pred, axis=1)\n",
    "Y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(Y_true_labels, Y_pred_labels))\n",
    "\n",
    "#Visualization\n",
    "plot_performance(history=history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
