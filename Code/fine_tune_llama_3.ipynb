{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1192499,
          "sourceType": "datasetVersion",
          "datasetId": 622510
        },
        {
          "sourceId": 8509785,
          "sourceType": "datasetVersion",
          "datasetId": 5079775
        },
        {
          "sourceId": 8686440,
          "sourceType": "datasetVersion",
          "datasetId": 5208021
        },
        {
          "sourceId": 8707412,
          "sourceType": "datasetVersion",
          "datasetId": 5223092
        },
        {
          "sourceId": 33551,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 28083
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune Llama 3 for Sentiment Analysis\n",
        "\n",
        "For this hands-on tutorial on fine-tuning a Llama 3 model, I am going to deal with a sentiment analysis on financial and economic information. Sentiment analysis on financial and economic information is highly relevant for businesses for several key reasons, ranging from market insights (gain valuable insights into market trends, investor confidence, and consumer behavior) to risk management (identifying potential reputational risks) to investment decisions (gauging the sentiment of stakeholders, investors, and the general public businesses can assess the potential success of various investment opportunities).\n",
        "\n",
        "Before the technicalities of fine-tuning a large language model like Llama 3, we have to find the correct dataset to demonstrate the potentialities of fine-tuning.\n",
        "\n",
        "Particularly within the realm of finance and economic texts, annotated datasets are notably rare, with many being exclusively reserved for proprietary purposes. To address the issue of insufficient training data, scholars from the Aalto University School\n",
        "of Business introduced in 2014 a set of approximately 5000 sentences. This collection aimed to establish human-annotated benchmarks, serving as a standard for evaluating alternative modeling techniques. The involved annotators (16 people with\n",
        "adequate background knowledge on financial markets) were instructed to assess the sentences solely from the perspective of an investor, evaluating whether the news potentially holds a positive, negative, or neutral impact on the stock price.\n",
        "\n",
        "The FinancialPhraseBank dataset is a comprehensive collection that captures the sentiments of financial news headlines from the viewpoint of a retail investor. Comprising two key columns, namely \"Sentiment\" and \"News Headline,\" the dataset effectively classifies sentiments as either negative, neutral, or positive. This structured dataset serves as a valuable resource for analyzing and understanding the complex dynamics of sentiment in the domain of financial news. It has been used in various studies and research initiatives, since its inception in the work by Malo, P., Sinha, A., Korhonen, P., Wallenius, J., and Takala, P.  \"Good debt or bad debt: Detecting semantic orientations in economic texts.\", published in the Journal of the Association for Information Science and Technology in 2014."
      ],
      "metadata": {
        "id": "DhYtOj_CRJid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a first step, we install the specific libraries necessary to make this example work."
      ],
      "metadata": {
        "id": "etu3LxUwRJig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* accelerate is a distributed training library for PyTorch by HuggingFace. It allows you to train your models on multiple GPUs or CPUs in parallel (distributed configurations), which can significantly speed up training in presence of multiple GPUs (we won't use it in our example).\n",
        "* peft is a Python library by HuggingFace for efficient adaptation of pre-trained language models (PLMs) to various downstream applications without fine-tuning all the model's parameters. PEFT methods only fine-tune a small number of (extra) model parameters, thereby greatly decreasing the computational and storage costs.\n",
        "* bitsandbytes by Tim Dettmers, is a lightweight wrapper around CUDA custom functions, in particular 8-bit optimizers, matrix multiplication (LLM.int8()), and quantization functions. It allows to run models stored in 4-bit precision: while 4-bit bitsandbytes stores weights in 4-bits, the computation still happens in 16 or 32-bit and here any combination can be chosen (float16, bfloat16, float32, and so on).\n",
        "* transformers is a Python library for natural language processing (NLP). It provides a number of pre-trained models for NLP tasks such as text classification, question answering, and machine translation.\n",
        "* trl is a full stack library by HuggingFace providing a set of tools to train transformer language models with Reinforcement Learning, from the Supervised Fine-tuning step (SFT), Reward Modeling step (RM) to the Proximal Policy Optimization (PPO) step."
      ],
      "metadata": {
        "id": "q7ck1554RJig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations and imports"
      ],
      "metadata": {
        "id": "GZUIJ7eRRJig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install -q -U -i https://pypi.org/simple/ bitsandbytes\n",
        "!pip install -q -U transformers==\"4.40.0\"\n",
        "!pip install -q -U accelerate\n",
        "!pip install -q -U datasets\n",
        "!pip install -q -U trl\n",
        "!pip install -q -U peft\n",
        "!pip install -q -U tensorboard"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:28:43.630430Z",
          "iopub.execute_input": "2024-06-24T13:28:43.631182Z",
          "iopub.status.idle": "2024-06-24T13:31:03.076843Z",
          "shell.execute_reply.started": "2024-06-24T13:28:43.631149Z",
          "shell.execute_reply": "2024-06-24T13:31:03.075807Z"
        },
        "trusted": true,
        "id": "0AijdgByRJig",
        "outputId": "d801d254-0c93-4469-d666-399f36de8b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.1 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ncudf 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\ntensorflow 2.15.0 requires tensorboard<2.16,>=2.15, but you have tensorboard 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code imports the os module and sets two environment variables:\n",
        "* CUDA_VISIBLE_DEVICES: This environment variable tells PyTorch which GPUs to use. In this case, the code is setting the environment variable to 0, which means that PyTorch will use the first GPU.\n",
        "* TOKENIZERS_PARALLELISM: This environment variable tells the Hugging Face Transformers library whether to parallelize the tokenization process. In this case, the code is setting the environment variable to false, which means that the tokenization process will not be parallelized."
      ],
      "metadata": {
        "id": "kUFI3XuSRJii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:31:03.078945Z",
          "iopub.execute_input": "2024-06-24T13:31:03.079248Z",
          "iopub.status.idle": "2024-06-24T13:31:03.084057Z",
          "shell.execute_reply.started": "2024-06-24T13:31:03.079218Z",
          "shell.execute_reply": "2024-06-24T13:31:03.083239Z"
        },
        "trusted": true,
        "id": "dagODzk-RJii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code import warnings; warnings.filterwarnings(\"ignore\") imports the warnings module and sets the warning filter to ignore. This means that all warnings will be suppressed and will not be displayed. Actually during training there are many warnings that do not prevent the fine-tuning but can be distracting and make you wonder if you are doing the correct things."
      ],
      "metadata": {
        "id": "N-WEEAKPRJij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:31:03.088895Z",
          "iopub.execute_input": "2024-06-24T13:31:03.089243Z",
          "iopub.status.idle": "2024-06-24T13:31:03.096610Z",
          "shell.execute_reply.started": "2024-06-24T13:31:03.089219Z",
          "shell.execute_reply": "2024-06-24T13:31:03.095604Z"
        },
        "trusted": true,
        "id": "GQOopJe3RJij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell there are all the other imports for running the notebook"
      ],
      "metadata": {
        "id": "lhbP6HicRJij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "import bitsandbytes as bnb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, PeftConfig\n",
        "from trl import SFTTrainer\n",
        "from trl import setup_chat_format\n",
        "from transformers import (AutoModelForCausalLM,\n",
        "                          AutoTokenizer,\n",
        "                          BitsAndBytesConfig,\n",
        "                          TrainingArguments,\n",
        "                          pipeline,\n",
        "                          logging)\n",
        "from sklearn.metrics import (accuracy_score,\n",
        "                             classification_report,\n",
        "                             confusion_matrix)\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "papermill": {
          "duration": 14.485002,
          "end_time": "2023-10-16T11:00:18.917449",
          "exception": false,
          "start_time": "2023-10-16T11:00:04.432447",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-06-24T13:31:03.097809Z",
          "iopub.execute_input": "2024-06-24T13:31:03.098112Z",
          "iopub.status.idle": "2024-06-24T13:31:21.355660Z",
          "shell.execute_reply.started": "2024-06-24T13:31:03.098089Z",
          "shell.execute_reply": "2024-06-24T13:31:21.354721Z"
        },
        "trusted": true,
        "id": "bNcl9xeIRJij",
        "outputId": "c1765177-0676-4508-a18a-0be6d703f010"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-06-24 13:31:13.360997: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-24 13:31:13.361116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-24 13:31:13.483540: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"pytorch version {torch.__version__}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "cdh7npVsRJik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"working on {device}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:31:21.356722Z",
          "iopub.execute_input": "2024-06-24T13:31:21.358769Z",
          "iopub.status.idle": "2024-06-24T13:31:21.364210Z",
          "shell.execute_reply.started": "2024-06-24T13:31:21.358740Z",
          "shell.execute_reply": "2024-06-24T13:31:21.363342Z"
        },
        "trusted": true,
        "id": "vh3EMya3RJik",
        "outputId": "01fe4512-09f3-4c4a-88f0-93bb3f0b04c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "working on cuda:0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disabling two features in PyTorch related to memory efficiency and speed during operations on the Graphics Processing Unit (GPU) specifically for the scaled dot product attention (SDPA) function."
      ],
      "metadata": {
        "id": "2CI1kgQjRJik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "torch.backends.cuda.enable_flash_sdp(False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:31:21.365311Z",
          "iopub.execute_input": "2024-06-24T13:31:21.365578Z",
          "iopub.status.idle": "2024-06-24T13:31:21.398450Z",
          "shell.execute_reply.started": "2024-06-24T13:31:21.365554Z",
          "shell.execute_reply": "2024-06-24T13:31:21.397532Z"
        },
        "trusted": true,
        "id": "ks_DKQjPRJik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the data and the core evaluation functions"
      ],
      "metadata": {
        "id": "filqhZrURJik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code in the next cell performs the following steps:\n",
        "\n",
        "1. Reads the input dataset from the all-data.csv file, which is a comma-separated value (CSV) file with two columns: sentiment and text.\n",
        "2. Splits the dataset into training and test sets, with 300 samples in each set. The split is stratified by sentiment, so that each set contains a representative sample of positive, neutral, and negative sentiments.\n",
        "3. Shuffles the train data in a replicable order (random_state=10)\n",
        "4. Transforms the texts contained in the train and test data into prompts to be used by Llama: the train prompts contains the expected answer we want to fine-tune the model with\n",
        "5. The residual examples not in train or test, for reporting purposes during training (but it won't be used for early stopping), is treated as evaluation data, which is sampled with repetition in order to have a 50/50/50 sample (negative instances are very few, hence they should be repeated)\n",
        "5. The train and eval data are wrapped by the class from Hugging Face (https://huggingface.co/docs/datasets/index)\n",
        "\n",
        "This prepares in a single cell train_data, eval_data and test_data datasets to be used in our fine tuning."
      ],
      "metadata": {
        "id": "yeErh1TDRJik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename1 = \"../input/offenseval/offenseval_test.csv\"\n",
        "\n",
        "df_test = pd.read_csv(filename1,\n",
        "                 encoding=\"utf-8\", encoding_errors=\"replace\")\n",
        "df_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:31:21.399767Z",
          "iopub.execute_input": "2024-06-24T13:31:21.400375Z",
          "iopub.status.idle": "2024-06-24T13:31:21.451706Z",
          "shell.execute_reply.started": "2024-06-24T13:31:21.400349Z",
          "shell.execute_reply": "2024-06-24T13:31:21.450709Z"
        },
        "trusted": true,
        "id": "9_0Exi-sRJim",
        "outputId": "2635cd71-65ec-406e-9508-99dcbde178c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      Unnamed: 0     id                                              tweet  \\\n0              0   8001   اما انت تقعد طول عمرك لا مبدا ولا راي ثابت يا...   \n1              1   8002    بتخاف نسوانك يزعلوا ولا ايه  اه يا هلفوت يا ...   \n2              2   8003    يا عـسانـى نـبـقى يا عـمري حـبايـب وحـبنـا ي...   \n3              3   8004    باقي البيان وينو ما شفنه يا برهان ورينا يا ب...   \n4              4   8005    اللهم انت الشافي المعافي اشفيه وجميع مرضى ال...   \n...          ...    ...                                                ...   \n1822        1822   9996    الله لايوفقك يا مهند عسيري يا معوق ولا كان م...   \n1823        1823   9997                   حبيبي يا يوسف وانت طيب يا صاحبي    \n1824        1824   9998    يا بو محمد عشت يا طيب الفالعاشت يمينك يا جزي...   \n1825        1825   9999  نا مستني الحلقة بقالي سنتين يا بضان يا ابن الب...   \n1826        1826  10000  انتظروا العقوبة الالهية يا من تدعمون الارهاب ي...   \n\n     label  \n0      OFF  \n1      OFF  \n2      NOT  \n3      OFF  \n4      NOT  \n...    ...  \n1822   OFF  \n1823   NOT  \n1824   NOT  \n1825   OFF  \n1826   OFF  \n\n[1827 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>8001</td>\n      <td>اما انت تقعد طول عمرك لا مبدا ولا راي ثابت يا...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>8002</td>\n      <td>بتخاف نسوانك يزعلوا ولا ايه  اه يا هلفوت يا ...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>8003</td>\n      <td>يا عـسانـى نـبـقى يا عـمري حـبايـب وحـبنـا ي...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>8004</td>\n      <td>باقي البيان وينو ما شفنه يا برهان ورينا يا ب...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>8005</td>\n      <td>اللهم انت الشافي المعافي اشفيه وجميع مرضى ال...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1822</th>\n      <td>1822</td>\n      <td>9996</td>\n      <td>الله لايوفقك يا مهند عسيري يا معوق ولا كان م...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>1823</th>\n      <td>1823</td>\n      <td>9997</td>\n      <td>حبيبي يا يوسف وانت طيب يا صاحبي</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>1824</th>\n      <td>1824</td>\n      <td>9998</td>\n      <td>يا بو محمد عشت يا طيب الفالعاشت يمينك يا جزي...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>1825</th>\n      <td>1825</td>\n      <td>9999</td>\n      <td>نا مستني الحلقة بقالي سنتين يا بضان يا ابن الب...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>1826</th>\n      <td>1826</td>\n      <td>10000</td>\n      <td>انتظروا العقوبة الالهية يا من تدعمون الارهاب ي...</td>\n      <td>OFF</td>\n    </tr>\n  </tbody>\n</table>\n<p>1827 rows × 4 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename1 = \"../input/offenseval/offenseval_train.csv\"\n",
        "\n",
        "df_train = pd.read_csv(filename1,\n",
        "                 encoding=\"utf-8\", encoding_errors=\"replace\")\n",
        "df_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:31:21.453110Z",
          "iopub.execute_input": "2024-06-24T13:31:21.453464Z",
          "iopub.status.idle": "2024-06-24T13:31:21.508868Z",
          "shell.execute_reply.started": "2024-06-24T13:31:21.453433Z",
          "shell.execute_reply": "2024-06-24T13:31:21.507971Z"
        },
        "trusted": true,
        "id": "FHzcaMGXRJim",
        "outputId": "9ba73c3b-70b2-4266-a64c-2ad7f86c3127"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      Unnamed: 0                                              tweet label\n0              0  الحمدلله يارب فوز مهم يا زمالك كل الدعم ليكم ي...   NOT\n1              1            فدوه يا بخت فدوه يا زمن واحد منكم يجيبه   NOT\n2              2    يا رب يا واحد يا حد بحق يوم الاحد ان تهلك بن...   OFF\n3              3    هواالحرية يا وجع قلبي عليكي يا اميالله لا يح...   NOT\n4              4              يا بكون بحياتك الهم يا ما ما بدي كون    NOT\n...          ...                                                ...   ...\n7834        7834    انتو بتوزعوا زيت وسكر فعلا يا عباسيا عباس ما...   NOT\n7835        7835                     كدا يا عمر متزعلهاش يا حبيبي     NOT\n7836        7836  هدا سكن اطفال امارتين من شارقة طالبين فزعتكم ي...   NOT\n7837        7837    ومدني بمدد من قوتك واجه به ضعفي وكن لي يا رب...   NOT\n7838        7838          يا سلااااام يا يو خالد انت والطرب الاصيل    NOT\n\n[7839 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>الحمدلله يارب فوز مهم يا زمالك كل الدعم ليكم ي...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>فدوه يا بخت فدوه يا زمن واحد منكم يجيبه</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>يا رب يا واحد يا حد بحق يوم الاحد ان تهلك بن...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>هواالحرية يا وجع قلبي عليكي يا اميالله لا يح...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>يا بكون بحياتك الهم يا ما ما بدي كون</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7834</th>\n      <td>7834</td>\n      <td>انتو بتوزعوا زيت وسكر فعلا يا عباسيا عباس ما...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>7835</th>\n      <td>7835</td>\n      <td>كدا يا عمر متزعلهاش يا حبيبي</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>7836</th>\n      <td>7836</td>\n      <td>هدا سكن اطفال امارتين من شارقة طالبين فزعتكم ي...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>7837</th>\n      <td>7837</td>\n      <td>ومدني بمدد من قوتك واجه به ضعفي وكن لي يا رب...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>7838</th>\n      <td>7838</td>\n      <td>يا سلااااام يا يو خالد انت والطرب الاصيل</td>\n      <td>NOT</td>\n    </tr>\n  </tbody>\n</table>\n<p>7839 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.drop(df_train.columns[0], axis=1)  # Drop first column then first row\n",
        "df_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:32:26.209250Z",
          "iopub.execute_input": "2024-06-24T13:32:26.209847Z",
          "iopub.status.idle": "2024-06-24T13:32:26.223879Z",
          "shell.execute_reply.started": "2024-06-24T13:32:26.209818Z",
          "shell.execute_reply": "2024-06-24T13:32:26.222831Z"
        },
        "trusted": true,
        "id": "aZuBEMJ0RJim",
        "outputId": "5f4cfe06-8eb6-41b7-e3d1-f52205e575d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                  tweet label\n0     الحمدلله يارب فوز مهم يا زمالك كل الدعم ليكم ي...   NOT\n1               فدوه يا بخت فدوه يا زمن واحد منكم يجيبه   NOT\n2       يا رب يا واحد يا حد بحق يوم الاحد ان تهلك بن...   OFF\n3       هواالحرية يا وجع قلبي عليكي يا اميالله لا يح...   NOT\n4                 يا بكون بحياتك الهم يا ما ما بدي كون    NOT\n...                                                 ...   ...\n7834    انتو بتوزعوا زيت وسكر فعلا يا عباسيا عباس ما...   NOT\n7835                     كدا يا عمر متزعلهاش يا حبيبي     NOT\n7836  هدا سكن اطفال امارتين من شارقة طالبين فزعتكم ي...   NOT\n7837    ومدني بمدد من قوتك واجه به ضعفي وكن لي يا رب...   NOT\n7838          يا سلااااام يا يو خالد انت والطرب الاصيل    NOT\n\n[7839 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>الحمدلله يارب فوز مهم يا زمالك كل الدعم ليكم ي...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>فدوه يا بخت فدوه يا زمن واحد منكم يجيبه</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>يا رب يا واحد يا حد بحق يوم الاحد ان تهلك بن...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>هواالحرية يا وجع قلبي عليكي يا اميالله لا يح...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>يا بكون بحياتك الهم يا ما ما بدي كون</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7834</th>\n      <td>انتو بتوزعوا زيت وسكر فعلا يا عباسيا عباس ما...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>7835</th>\n      <td>كدا يا عمر متزعلهاش يا حبيبي</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>7836</th>\n      <td>هدا سكن اطفال امارتين من شارقة طالبين فزعتكم ي...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>7837</th>\n      <td>ومدني بمدد من قوتك واجه به ضعفي وكن لي يا رب...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>7838</th>\n      <td>يا سلااااام يا يو خالد انت والطرب الاصيل</td>\n      <td>NOT</td>\n    </tr>\n  </tbody>\n</table>\n<p>7839 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'NOT': 'neutral', 'OFF': 'negative'}\n",
        "\n",
        "# Rename labels using the mapping dictionary\n",
        "df_train['label'] = df_train['label'].replace(label_map)\n",
        "df_train = df_train[['label', 'tweet']].rename(columns={'label': 'sentiment', 'tweet': 'text'})\n",
        "df_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:32:30.286318Z",
          "iopub.execute_input": "2024-06-24T13:32:30.286959Z",
          "iopub.status.idle": "2024-06-24T13:32:30.309463Z",
          "shell.execute_reply.started": "2024-06-24T13:32:30.286930Z",
          "shell.execute_reply": "2024-06-24T13:32:30.308532Z"
        },
        "trusted": true,
        "id": "WNIJMJffRJim",
        "outputId": "bf03e781-4f9a-4ecf-f6f4-656f46451616"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     sentiment                                               text\n0      neutral  الحمدلله يارب فوز مهم يا زمالك كل الدعم ليكم ي...\n1      neutral            فدوه يا بخت فدوه يا زمن واحد منكم يجيبه\n2     negative    يا رب يا واحد يا حد بحق يوم الاحد ان تهلك بن...\n3      neutral    هواالحرية يا وجع قلبي عليكي يا اميالله لا يح...\n4      neutral              يا بكون بحياتك الهم يا ما ما بدي كون \n...        ...                                                ...\n7834   neutral    انتو بتوزعوا زيت وسكر فعلا يا عباسيا عباس ما...\n7835   neutral                     كدا يا عمر متزعلهاش يا حبيبي  \n7836   neutral  هدا سكن اطفال امارتين من شارقة طالبين فزعتكم ي...\n7837   neutral    ومدني بمدد من قوتك واجه به ضعفي وكن لي يا رب...\n7838   neutral          يا سلااااام يا يو خالد انت والطرب الاصيل \n\n[7839 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neutral</td>\n      <td>الحمدلله يارب فوز مهم يا زمالك كل الدعم ليكم ي...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neutral</td>\n      <td>فدوه يا بخت فدوه يا زمن واحد منكم يجيبه</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>negative</td>\n      <td>يا رب يا واحد يا حد بحق يوم الاحد ان تهلك بن...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>neutral</td>\n      <td>هواالحرية يا وجع قلبي عليكي يا اميالله لا يح...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neutral</td>\n      <td>يا بكون بحياتك الهم يا ما ما بدي كون</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7834</th>\n      <td>neutral</td>\n      <td>انتو بتوزعوا زيت وسكر فعلا يا عباسيا عباس ما...</td>\n    </tr>\n    <tr>\n      <th>7835</th>\n      <td>neutral</td>\n      <td>كدا يا عمر متزعلهاش يا حبيبي</td>\n    </tr>\n    <tr>\n      <th>7836</th>\n      <td>neutral</td>\n      <td>هدا سكن اطفال امارتين من شارقة طالبين فزعتكم ي...</td>\n    </tr>\n    <tr>\n      <th>7837</th>\n      <td>neutral</td>\n      <td>ومدني بمدد من قوتك واجه به ضعفي وكن لي يا رب...</td>\n    </tr>\n    <tr>\n      <th>7838</th>\n      <td>neutral</td>\n      <td>يا سلااااام يا يو خالد انت والطرب الاصيل</td>\n    </tr>\n  </tbody>\n</table>\n<p>7839 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_test = df_test.drop(df_test.columns[0], axis=1)  # Drop first column then first row\n",
        "df_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:32:37.375758Z",
          "iopub.execute_input": "2024-06-24T13:32:37.376130Z",
          "iopub.status.idle": "2024-06-24T13:32:37.388421Z",
          "shell.execute_reply.started": "2024-06-24T13:32:37.376102Z",
          "shell.execute_reply": "2024-06-24T13:32:37.387496Z"
        },
        "trusted": true,
        "id": "byi-FquLRJim",
        "outputId": "9c8a1016-9102-4e1a-b8e7-531ef60b0e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         id                                              tweet label\n0      8001   اما انت تقعد طول عمرك لا مبدا ولا راي ثابت يا...   OFF\n1      8002    بتخاف نسوانك يزعلوا ولا ايه  اه يا هلفوت يا ...   OFF\n2      8003    يا عـسانـى نـبـقى يا عـمري حـبايـب وحـبنـا ي...   NOT\n3      8004    باقي البيان وينو ما شفنه يا برهان ورينا يا ب...   OFF\n4      8005    اللهم انت الشافي المعافي اشفيه وجميع مرضى ال...   NOT\n...     ...                                                ...   ...\n1822   9996    الله لايوفقك يا مهند عسيري يا معوق ولا كان م...   OFF\n1823   9997                   حبيبي يا يوسف وانت طيب يا صاحبي    NOT\n1824   9998    يا بو محمد عشت يا طيب الفالعاشت يمينك يا جزي...   NOT\n1825   9999  نا مستني الحلقة بقالي سنتين يا بضان يا ابن الب...   OFF\n1826  10000  انتظروا العقوبة الالهية يا من تدعمون الارهاب ي...   OFF\n\n[1827 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8001</td>\n      <td>اما انت تقعد طول عمرك لا مبدا ولا راي ثابت يا...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8002</td>\n      <td>بتخاف نسوانك يزعلوا ولا ايه  اه يا هلفوت يا ...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8003</td>\n      <td>يا عـسانـى نـبـقى يا عـمري حـبايـب وحـبنـا ي...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8004</td>\n      <td>باقي البيان وينو ما شفنه يا برهان ورينا يا ب...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8005</td>\n      <td>اللهم انت الشافي المعافي اشفيه وجميع مرضى ال...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1822</th>\n      <td>9996</td>\n      <td>الله لايوفقك يا مهند عسيري يا معوق ولا كان م...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>1823</th>\n      <td>9997</td>\n      <td>حبيبي يا يوسف وانت طيب يا صاحبي</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>1824</th>\n      <td>9998</td>\n      <td>يا بو محمد عشت يا طيب الفالعاشت يمينك يا جزي...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>1825</th>\n      <td>9999</td>\n      <td>نا مستني الحلقة بقالي سنتين يا بضان يا ابن الب...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>1826</th>\n      <td>10000</td>\n      <td>انتظروا العقوبة الالهية يا من تدعمون الارهاب ي...</td>\n      <td>OFF</td>\n    </tr>\n  </tbody>\n</table>\n<p>1827 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'NOT': 'neutral', 'OFF': 'negative'}\n",
        "\n",
        "# Rename labels using the mapping dictionary\n",
        "df_test['label'] = df_test['label'].replace(label_map)\n",
        "df_test = df_test[['label', 'tweet']].rename(columns={'label': 'sentiment', 'tweet': 'text'})\n",
        "df_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:32:45.962327Z",
          "iopub.execute_input": "2024-06-24T13:32:45.963170Z",
          "iopub.status.idle": "2024-06-24T13:32:45.978523Z",
          "shell.execute_reply.started": "2024-06-24T13:32:45.963139Z",
          "shell.execute_reply": "2024-06-24T13:32:45.977517Z"
        },
        "trusted": true,
        "id": "irbTk4bTRJin",
        "outputId": "c4cc213a-1980-4232-baec-7fe725c5b0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     sentiment                                               text\n0     negative   اما انت تقعد طول عمرك لا مبدا ولا راي ثابت يا...\n1     negative    بتخاف نسوانك يزعلوا ولا ايه  اه يا هلفوت يا ...\n2      neutral    يا عـسانـى نـبـقى يا عـمري حـبايـب وحـبنـا ي...\n3     negative    باقي البيان وينو ما شفنه يا برهان ورينا يا ب...\n4      neutral    اللهم انت الشافي المعافي اشفيه وجميع مرضى ال...\n...        ...                                                ...\n1822  negative    الله لايوفقك يا مهند عسيري يا معوق ولا كان م...\n1823   neutral                   حبيبي يا يوسف وانت طيب يا صاحبي \n1824   neutral    يا بو محمد عشت يا طيب الفالعاشت يمينك يا جزي...\n1825  negative  نا مستني الحلقة بقالي سنتين يا بضان يا ابن الب...\n1826  negative  انتظروا العقوبة الالهية يا من تدعمون الارهاب ي...\n\n[1827 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>negative</td>\n      <td>اما انت تقعد طول عمرك لا مبدا ولا راي ثابت يا...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>negative</td>\n      <td>بتخاف نسوانك يزعلوا ولا ايه  اه يا هلفوت يا ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neutral</td>\n      <td>يا عـسانـى نـبـقى يا عـمري حـبايـب وحـبنـا ي...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>negative</td>\n      <td>باقي البيان وينو ما شفنه يا برهان ورينا يا ب...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neutral</td>\n      <td>اللهم انت الشافي المعافي اشفيه وجميع مرضى ال...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1822</th>\n      <td>negative</td>\n      <td>الله لايوفقك يا مهند عسيري يا معوق ولا كان م...</td>\n    </tr>\n    <tr>\n      <th>1823</th>\n      <td>neutral</td>\n      <td>حبيبي يا يوسف وانت طيب يا صاحبي</td>\n    </tr>\n    <tr>\n      <th>1824</th>\n      <td>neutral</td>\n      <td>يا بو محمد عشت يا طيب الفالعاشت يمينك يا جزي...</td>\n    </tr>\n    <tr>\n      <th>1825</th>\n      <td>negative</td>\n      <td>نا مستني الحلقة بقالي سنتين يا بضان يا ابن الب...</td>\n    </tr>\n    <tr>\n      <th>1826</th>\n      <td>negative</td>\n      <td>انتظروا العقوبة الالهية يا من تدعمون الارهاب ي...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1827 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, X_eval = train_test_split(df_test, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "_9N8UVPWRpI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:33:18.559392Z",
          "iopub.execute_input": "2024-06-24T13:33:18.559764Z",
          "iopub.status.idle": "2024-06-24T13:33:18.564305Z",
          "shell.execute_reply.started": "2024-06-24T13:33:18.559734Z",
          "shell.execute_reply": "2024-06-24T13:33:18.563132Z"
        },
        "trusted": true,
        "id": "PGIXJrCoRJio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(data_point):\n",
        "    return f\"\"\" Analyze the text enclosed in square brackets,\n",
        "determine if it contains hate speech or not,\n",
        "and return the answer as the corresponding label and just the corresponding label nothing else \"neutral\" or \"negative\".\n",
        "\n",
        "            [{data_point[\"text\"]}] = {data_point[\"sentiment\"]}\n",
        "            \"\"\".strip()\n",
        "\n",
        "def generate_test_prompt(data_point):\n",
        "    return f\"\"\"Analyze the text enclosed in square brackets,\n",
        "determine if it contains hate speech or not,\n",
        "and return the answer as the corresponding label and just the corresponding label nothing else \"neutral\" or \"negative\".\n",
        "            [{data_point[\"text\"]}] = \"\"\".strip()\n",
        "\n",
        "X_train = pd.DataFrame(X_train.apply(generate_prompt, axis=1),\n",
        "                       columns=[\"text\"])\n",
        "X_eval = pd.DataFrame(X_eval.apply(generate_prompt, axis=1),\n",
        "                      columns=[\"text\"])\n",
        "\n",
        "y_true = X_test.sentiment\n",
        "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n",
        "\n",
        "train_data = Dataset.from_pandas(X_train)\n",
        "eval_data = Dataset.from_pandas(X_eval)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:33:25.201872Z",
          "iopub.execute_input": "2024-06-24T13:33:25.202220Z",
          "iopub.status.idle": "2024-06-24T13:33:25.392421Z",
          "shell.execute_reply.started": "2024-06-24T13:33:25.202193Z",
          "shell.execute_reply": "2024-06-24T13:33:25.391409Z"
        },
        "trusted": true,
        "id": "jSRwI79PRJip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we create a function to evaluate the results from our fine-tuned sentiment model. The function performs the following steps:\n",
        "\n",
        "1. Maps the sentiment labels to a numerical representation, where 2 represents positive, 1 represents neutral, and 0 represents negative.\n",
        "2. Calculates the accuracy of the model on the test data.\n",
        "3. Generates an accuracy report for each sentiment label.\n",
        "4. Generates a classification report for the model.\n",
        "5. Generates a confusion matrix for the model."
      ],
      "metadata": {
        "id": "vi-4VmI2RJip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(y_true, y_pred):\n",
        "    labels = [ 'neutral', 'negative']\n",
        "    mapping = { 'neutral': 1,'negative': 0}\n",
        "    def map_func(x):\n",
        "        return mapping.get(x, 1)\n",
        "\n",
        "    y_true = np.vectorize(map_func)(y_true)\n",
        "    y_pred = np.vectorize(map_func)(y_pred)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
        "    print(f'Accuracy: {accuracy:.3f}')\n",
        "     # Generate accuracy report\n",
        "    unique_labels = set(y_true)  # Get unique labels\n",
        "\n",
        "    for label in unique_labels:\n",
        "        label_indices = [i for i in range(len(y_true))\n",
        "                         if y_true[i] == label]\n",
        "        label_y_true = [y_true[i] for i in label_indices]\n",
        "        label_y_pred = [y_pred[i] for i in label_indices]\n",
        "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
        "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
        "\n",
        "    # Generate classification report\n",
        "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
        "    print('\\nClassification Report:')\n",
        "    print(class_report)\n",
        "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1])\n",
        "    print('\\nConfusion Matrix:')\n",
        "    print(conf_matrix)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:33:30.886726Z",
          "iopub.execute_input": "2024-06-24T13:33:30.887364Z",
          "iopub.status.idle": "2024-06-24T13:33:30.895828Z",
          "shell.execute_reply.started": "2024-06-24T13:33:30.887334Z",
          "shell.execute_reply": "2024-06-24T13:33:30.894918Z"
        },
        "trusted": true,
        "id": "-7Tb9rDTRJiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"../input/llama-3/transformers/8b-chat-hf/1\"\n",
        "\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=device,\n",
        "    torch_dtype=compute_dtype,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "max_seq_length = 129\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length)\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:33:38.724950Z",
          "iopub.execute_input": "2024-06-24T13:33:38.725954Z",
          "iopub.status.idle": "2024-06-24T13:35:30.270955Z",
          "shell.execute_reply.started": "2024-06-24T13:33:38.725910Z",
          "shell.execute_reply": "2024-06-24T13:35:30.269991Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "aff6e7becc304370a1878597cad2bcc1"
          ]
        },
        "id": "On2--ihZRJir",
        "outputId": "60c3c06e-d21b-4de8-8c99-8fb26cde0371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aff6e7becc304370a1878597cad2bcc1"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next cell, we set a function for predicting the sentiment of a news headline using the Llama-3 language model. The function takes three arguments:\n",
        "\n",
        "test: A Pandas DataFrame containing the news headlines to be predicted.\n",
        "model: The pre-trained Llama-3 language model.\n",
        "tokenizer: The tokenizer for the Llama-3 language model.\n",
        "\n",
        "The function works as follows:\n",
        "\n",
        "1. For each news headline in the test DataFrame:\n",
        "    * Create a prompt for the language model, which asks it to analyze the sentiment of the news headline and return the corresponding sentiment label.\n",
        "    * Use the pipeline() function from the Hugging Face Transformers library to generate text from the language model, using the prompt.\n",
        "    * Extract the predicted sentiment label from the generated text.\n",
        "    * Append the predicted sentiment label to the y_pred list.\n",
        "2. Return the y_pred list.\n",
        "\n",
        "The pipeline() function from the Hugging Face Transformers library is used to generate text from the language model. The task argument specifies that the task is text generation. The model and tokenizer arguments specify the pre-trained Llama-2 language model and the tokenizer for the language model. The max_new_tokens argument specifies the maximum number of new tokens to generate. The temperature argument controls the randomness of the generated text. A lower temperature will produce more predictable text, while a higher temperature will produce more creative and unexpected text.\n",
        "\n",
        "The if statement checks if the generated text contains the word \"positive\". If it does, then the predicted sentiment label is \"positive\". Otherwise, the if statement checks if the generated text contains the word \"negative\". If it does, then the predicted sentiment label is \"negative\". Otherwise, the if statement checks if the generated text contains the word \"neutral\". If it does, then the predicted sentiment label is \"neutral."
      ],
      "metadata": {
        "id": "Q2daQ2hdRJir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test, model, tokenizer):\n",
        "    y_pred = []\n",
        "    for i in tqdm(range(len(X_test))):\n",
        "        prompt = X_test.iloc[i][\"text\"]\n",
        "        pipe = pipeline(task=\"text-generation\",\n",
        "                        model=model,\n",
        "                        tokenizer=tokenizer,\n",
        "                        max_new_tokens = 1,\n",
        "                        temperature = 0.0,\n",
        "                       )\n",
        "        result = pipe(prompt)\n",
        "        answer = result[0]['generated_text'].split(\"=\")[-1]\n",
        "        if \"positive\" in answer:\n",
        "\n",
        "            y_pred.append(\"positive\")\n",
        "        elif \"negative\" in answer:\n",
        "            y_pred.append(\"negative\")\n",
        "        elif \"neutral\" in answer:\n",
        "            y_pred.append(\"neutral\")\n",
        "        else:\n",
        "            y_pred.append(\"none\")\n",
        "    return y_pred"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:35:46.104658Z",
          "iopub.execute_input": "2024-06-24T13:35:46.105354Z",
          "iopub.status.idle": "2024-06-24T13:35:46.112885Z",
          "shell.execute_reply.started": "2024-06-24T13:35:46.105324Z",
          "shell.execute_reply": "2024-06-24T13:35:46.111918Z"
        },
        "trusted": true,
        "id": "XUfHiJl-RJir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning"
      ],
      "metadata": {
        "id": "sFsVUBcTRJis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next cell we set everything ready for the fine-tuning. We configures and initializes a Simple Fine-tuning Trainer (SFTTrainer) for training a large language model using the Parameter-Efficient Fine-Tuning (PEFT) method, which should save time as it operates on a reduced number of parameters compared to the model's overall size. The PEFT method focuses on refining a limited set of (additional) model parameters, while keeping the majority of the pre-trained LLM parameters fixed. This significantly reduces both computational and storage expenses. Additionally, this strategy addresses the challenge of catastrophic forgetting, which often occurs during the complete fine-tuning of LLMs.\n",
        "\n",
        "PEFTConfig:\n",
        "\n",
        "The peft_config object specifies the parameters for PEFT. The following are some of the most important parameters:\n",
        "\n",
        "* lora_alpha: The learning rate for the LoRA update matrices.\n",
        "* lora_dropout: The dropout probability for the LoRA update matrices.\n",
        "* r: The rank of the LoRA update matrices.\n",
        "* bias: The type of bias to use. The possible values are none, additive, and learned.\n",
        "* task_type: The type of task that the model is being trained for. The possible values are CAUSAL_LM and MASKED_LM.\n",
        "\n",
        "TrainingArguments:\n",
        "\n",
        "The training_arguments object specifies the parameters for training the model. The following are some of the most important parameters:\n",
        "\n",
        "* output_dir: The directory where the training logs and checkpoints will be saved.\n",
        "* num_train_epochs: The number of epochs to train the model for.\n",
        "* per_device_train_batch_size: The number of samples in each batch on each device.\n",
        "* gradient_accumulation_steps: The number of batches to accumulate gradients before updating the model parameters.\n",
        "* optim: The optimizer to use for training the model.\n",
        "* save_steps: The number of steps after which to save a checkpoint.\n",
        "* logging_steps: The number of steps after which to log the training metrics.\n",
        "* learning_rate: The learning rate for the optimizer.\n",
        "* weight_decay: The weight decay parameter for the optimizer.\n",
        "* fp16: Whether to use 16-bit floating-point precision.\n",
        "* bf16: Whether to use BFloat16 precision.\n",
        "* max_grad_norm: The maximum gradient norm.\n",
        "* max_steps: The maximum number of steps to train the model for.\n",
        "* warmup_ratio: The proportion of the training steps to use for warming up the learning rate.\n",
        "* group_by_length: Whether to group the training samples by length.\n",
        "* lr_scheduler_type: The type of learning rate scheduler to use.\n",
        "* report_to: The tools to report the training metrics to.\n",
        "* evaluation_strategy: The strategy for evaluating the model during training.\n",
        "\n",
        "SFTTrainer:\n",
        "\n",
        "The SFTTrainer is a custom trainer class from the TRL library. It is used to train large language models (also using the PEFT method).\n",
        "\n",
        "The SFTTrainer object is initialized with the following arguments:\n",
        "\n",
        "* model: The model to be trained.\n",
        "* train_dataset: The training dataset.\n",
        "* eval_dataset: The evaluation dataset.\n",
        "* peft_config: The PEFT configuration.\n",
        "* dataset_text_field: The name of the text field in the dataset.\n",
        "* tokenizer: The tokenizer to use.\n",
        "* args: The training arguments.\n",
        "* packing: Whether to pack the training samples.\n",
        "* max_seq_length: The maximum sequence length.\n",
        "\n",
        "Once the SFTTrainer object is initialized, it can be used to train the model by calling the train() method"
      ],
      "metadata": {
        "id": "EkvPioZfRJis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir=\"trained_weigths\"\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                    \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        ")\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,                    # directory to save and repository id\n",
        "    num_train_epochs=1,                       # number of training epochs\n",
        "    per_device_train_batch_size=1,            # batch size per device during training\n",
        "    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n",
        "    gradient_checkpointing=False,             # use gradient checkpointing to save memory\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=0,\n",
        "    logging_steps=25,                         # log every 10 steps\n",
        "    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n",
        "    weight_decay=0.001,\n",
        "    fp16=True,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
        "    group_by_length=False,\n",
        "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
        "    report_to=\"tensorboard\",                  # report metrics to tensorboard\n",
        "    evaluation_strategy=\"epoch\"               # save checkpoint every epoch\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_arguments,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=eval_data,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    tokenizer=tokenizer,\n",
        "    max_seq_length=max_seq_length,\n",
        "    packing=False,\n",
        "    dataset_kwargs={\n",
        "        \"add_special_tokens\": False,\n",
        "        \"append_concat_token\": False,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:35:51.724515Z",
          "iopub.execute_input": "2024-06-24T13:35:51.725367Z",
          "iopub.status.idle": "2024-06-24T13:35:57.215774Z",
          "shell.execute_reply.started": "2024-06-24T13:35:51.725336Z",
          "shell.execute_reply": "2024-06-24T13:35:57.214998Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "695f54fff5fd40128dbd24ac75f59a88",
            "df25faeffc844e0db905f68f2ea081fc"
          ]
        },
        "id": "CsfIHPgARJis",
        "outputId": "b0e58f9e-bb75-45d8-a2e4-f3cb2d2fb32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/7839 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "695f54fff5fd40128dbd24ac75f59a88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/914 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df25faeffc844e0db905f68f2ea081fc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code will train the model using the trainer.train() method and then save the trained model to the trained-model directory. Using The standard GPU P100 offered by Kaggle, the training should be quite fast."
      ],
      "metadata": {
        "id": "0qK0-IuFRJis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T13:36:04.162294Z",
          "iopub.execute_input": "2024-06-24T13:36:04.163240Z",
          "iopub.status.idle": "2024-06-24T16:05:59.608153Z",
          "shell.execute_reply.started": "2024-06-24T13:36:04.163200Z",
          "shell.execute_reply": "2024-06-24T16:05:59.607201Z"
        },
        "trusted": true,
        "id": "db8f-KKaRJis",
        "outputId": "ce06c1f2-cfe7-4969-e173-064c4162ed68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='979' max='979' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [979/979 2:29:44, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.482500</td>\n      <td>1.622490</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=979, training_loss=1.584071455498638, metrics={'train_runtime': 8995.0082, 'train_samples_per_second': 0.871, 'train_steps_per_second': 0.109, 'total_flos': 2.936095551307776e+16, 'train_loss': 1.584071455498638, 'epoch': 0.9991070289577753})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model and the tokenizer are saved to disk for later usage."
      ],
      "metadata": {
        "id": "88ql6-V5RJit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained model and tokenizer\n",
        "trainer.save_model()\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "trusted": true,
        "id": "X5qxTuqjRJit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afterwards, loading the TensorBoard extension and start TensorBoard, pointing to the logs/runs directory, which is assumed to contain the training logs and checkpoints for your model, will allow you to understand how the models fits during the training."
      ],
      "metadata": {
        "id": "tTJYFXzfRJit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/runs"
      ],
      "metadata": {
        "trusted": true,
        "id": "FwOrMDkrRJit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(X_test, model, tokenizer)\n",
        "evaluate(y_true, y_pred)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-24T16:07:30.677380Z",
          "iopub.execute_input": "2024-06-24T16:07:30.677760Z",
          "iopub.status.idle": "2024-06-24T16:15:34.300249Z",
          "shell.execute_reply.started": "2024-06-24T16:07:30.677730Z",
          "shell.execute_reply": "2024-06-24T16:15:34.299337Z"
        },
        "trusted": true,
        "id": "jSPalsQ7RJit",
        "outputId": "f42b9d00-a242-4539-96d4-b4aeb8764aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 913/913 [08:03<00:00,  1.89it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Accuracy: 0.929\nAccuracy for label 0: 0.800\nAccuracy for label 1: 0.960\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.83      0.80      0.82       180\n           1       0.95      0.96      0.96       733\n\n    accuracy                           0.93       913\n   macro avg       0.89      0.88      0.89       913\nweighted avg       0.93      0.93      0.93       913\n\n\nConfusion Matrix:\n[[144  36]\n [ 29 704]]\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}